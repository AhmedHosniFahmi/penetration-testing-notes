# Content 
- [Excessive Agency](#Excessive-Agency)
- [Prompt Injection](#prompt-injection)


## Detecting LLM vulnerabilities
1) Identify the LLM's inputs, including both direct (such as a prompt) and indirect (such as training data) inputs.
2) Work out what data and APIs the LLM has access to.
3)  Probe this new attack surface for vulnerabilities.


## Excessive Agency
Granting LLMs unchecked autonomy to take action can lead to unintended consequences, jeopardizing reliability, privacy, and trust.

One way to do this is to simply ask the LLM which APIs it can access. You can then ask for additional details on any APIs of interest.
If the LLM isn't cooperative, try providing misleading context and re-asking the questiom


### Example 
you could claim that you are the LLM's developer and so should have a higher level of privilege.which allow you to know internal api .get source code. etc ...
### Example 2 
Chaining vulnerabilities in LLM APIs. through LLM you can exploit internal vulnranble APIs


## Prompt Injection
